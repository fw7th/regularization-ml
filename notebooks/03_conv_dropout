{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOs4AkFGnEbY5I1+RqnZBRR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O3nvZ2kwXSOM","executionInfo":{"status":"ok","timestamp":1758679038167,"user_tz":-60,"elapsed":11404,"user":{"displayName":"David Okosa","userId":"00279339004346410402"}},"outputId":"d420dc37-3a9f-4a69-c39e-88054bad8124"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting thop\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from thop) (2.8.0+cu126)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.19.1)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->thop) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->thop) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.4.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->thop) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->thop) (3.0.2)\n","Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Installing collected packages: thop\n","Successfully installed thop-0.1.1.post2209072238\n"]}],"source":["!pip install thop"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l7dR3kJKYEsj","executionInfo":{"status":"ok","timestamp":1758679077659,"user_tz":-60,"elapsed":39486,"user":{"displayName":"David Okosa","userId":"00279339004346410402"}},"outputId":"2ecb702d-f4c7-4b10-c074-b9c7479098cc"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/regularization-ml/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j6HJBvUSYFnD","executionInfo":{"status":"ok","timestamp":1758679077764,"user_tz":-60,"elapsed":138,"user":{"displayName":"David Okosa","userId":"00279339004346410402"}},"outputId":"1815e213-7199-4dfb-bc89-690dec681f64"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/regularization-ml\n"]}]},{"cell_type":"code","source":["# importing all necessary libs and modules.\n","import torch\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","from config.paths import PathConfig # Path config\n","\n","from src.model import MiniCNN, ConvBlock, FCBlock\n","from src.train import trainModel\n","from src.data import CustomDataset, load_cifar_10_data, check_data_loading, Loader, class_to_idx\n","from src.visualizations import plotFmaps_and_activationHist, plotCurves\n","from src.utils import unpickle, loadWeights, readJson, genError, saveHistory, evalModel"],"metadata":{"id":"OynJIfdzYGjM","executionInfo":{"status":"ok","timestamp":1758679095288,"user_tz":-60,"elapsed":17522,"user":{"displayName":"David Okosa","userId":"00279339004346410402"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\""],"metadata":{"id":"YCpD0EZUYGgN","executionInfo":{"status":"ok","timestamp":1758679095346,"user_tz":-60,"elapsed":33,"user":{"displayName":"David Okosa","userId":"00279339004346410402"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["paths = PathConfig(\"regularization-ml\", \"regularization-data\")\n","PROJECT_DIR = paths.project\n","DATA_DIR = paths.data\n","BASE_DIR = paths.root"],"metadata":{"id":"c4qS5-WzYGdI","executionInfo":{"status":"ok","timestamp":1758679095377,"user_tz":-60,"elapsed":26,"user":{"displayName":"David Okosa","userId":"00279339004346410402"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Copy once from Drive\n","!cp $DATA_DIR/cifar-10-python.tar.gz /content/\n","\n","# Extract locally\n","!mkdir /content/dataset/\n","!tar -xzf /content/cifar-10-python.tar.gz -C /content/dataset/"],"metadata":{"id":"Al9P-tzOYGPt","executionInfo":{"status":"ok","timestamp":1758679101516,"user_tz":-60,"elapsed":6148,"user":{"displayName":"David Okosa","userId":"00279339004346410402"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Defining the layers for the baseline model\n","base_conv_layers = [\n","    ConvBlock(3, 64, pool=False),\n","    ConvBlock(64, 64),\n","    ConvBlock(64, 128, pool=False, dropout=True, drop_val=0.1),\n","    ConvBlock(128, 128)\n","]\n","\n","base_fc_layers = [\n","    FCBlock(128, 64),\n","    torch.nn.Linear(64, 10)\n","]\n","\n","conv_1_model = MiniCNN(base_conv_layers, base_fc_layers)"],"metadata":{"id":"J29zJQcdYZ50","executionInfo":{"status":"ok","timestamp":1758679101550,"user_tz":-60,"elapsed":32,"user":{"displayName":"David Okosa","userId":"00279339004346410402"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["LOCAL_DATA = f\"{BASE_DIR}/dataset\" # path to cifar-10 dataset\n","train_data, train_labels, val_data, val_labels, test_data, test_labels = load_cifar_10_data(LOCAL_DATA)"],"metadata":{"id":"jePnUPffYZ3Y","executionInfo":{"status":"ok","timestamp":1758679101888,"user_tz":-60,"elapsed":334,"user":{"displayName":"David Okosa","userId":"00279339004346410402"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Creates train, test, and val loaders\n","train_loader, val_loader, test_loader = Loader(train_data, train_labels, val_data, val_labels, test_data, test_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ne6nlmgvYZ02","executionInfo":{"status":"ok","timestamp":1758679103257,"user_tz":-60,"elapsed":1360,"user":{"displayName":"David Okosa","userId":"00279339004346410402"}},"outputId":"baa31deb-b906-4e6b-80aa-d1099d6552ac"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting Data Loading...\n","‚úÖ CUDA available: Tesla T4\n","   Memory: 15095 MB\n","üìÅ Loading datasets...\n","‚úÖ Datasets loaded successfully\n","Training samples: 40000\n","Validation samples: 10000\n","Batch size: 64\n","üîç Testing data loading...\n","‚úÖ Train batch shape: torch.Size([64, 3, 32, 32]), Labels: torch.Size([64])\n","   Input range: [-1.989, 2.126]\n","   Label range: [0, 9]\n","‚úÖ Val batch shape: torch.Size([64, 3, 32, 32]), Labels: torch.Size([64])\n"]}]},{"cell_type":"code","source":["\"\"\"\n","history_conv1 = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n","model_type = \"conv0.1\"\n","path = f\"{DATA_DIR}/weights\"\n","conv_1_model = trainModel(conv_1_model, history_conv1, train_loader, val_loader, model_type, path)\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bEIAVkB6YZua","executionInfo":{"status":"ok","timestamp":1758681884875,"user_tz":-60,"elapsed":2241497,"user":{"displayName":"David Okosa","userId":"00279339004346410402"}},"outputId":"ea1b88e1-c37d-43fb-aac3-1f8fc3826dd4"},"execution_count":11,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Using device: cuda\n","--------------------------------------------------\n","Epoch 1/70\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[""]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 1.9058, Train Acc: 0.2656\n","Val Loss: 1.7103, Val Acc: 0.3388\n","Best Val Acc: 0.3388 | LR: 0.001000\n","Time: 41.6s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 2/70\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[""]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["üíæ Saved best model!\n","Train Loss: 1.5948, Train Acc: 0.3998\n","Val Loss: 1.4058, Val Acc: 0.4847\n","Best Val Acc: 0.4847 | LR: 0.001000\n","Time: 38.2s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 3/70\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[""]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["üíæ Saved best model!\n","Train Loss: 1.3710, Train Acc: 0.4977\n","Val Loss: 1.2638, Val Acc: 0.5397\n","Best Val Acc: 0.5397 | LR: 0.001000\n","Time: 39.6s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 4/70\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[""]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["üíæ Saved best model!\n","Train Loss: 1.2259, Train Acc: 0.5558\n","Val Loss: 1.1004, Val Acc: 0.6038\n","Best Val Acc: 0.6038 | LR: 0.001000\n","Time: 42.4s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 5/70\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[""]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["üíæ Saved best model!\n","Train Loss: 1.1281, Train Acc: 0.5939\n","Val Loss: 1.0356, Val Acc: 0.6284\n","Best Val Acc: 0.6284 | LR: 0.001000\n","Time: 42.0s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 6/70\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[""]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["üíæ Saved best model!\n","Train Loss: 1.0543, Train Acc: 0.6216\n","Val Loss: 1.0158, Val Acc: 0.6424\n","Best Val Acc: 0.6424 | LR: 0.001000\n","Time: 40.8s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 7/70\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[""]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["üíæ Saved best model!\n","Train Loss: 0.9933, Train Acc: 0.6450\n","Val Loss: 0.9203, Val Acc: 0.6758\n","Best Val Acc: 0.6758 | LR: 0.001000\n","Time: 37.7s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 8/70\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[""]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["üíæ Saved best model!\n","Train Loss: 0.9389, Train Acc: 0.6680\n","Val Loss: 0.9016, Val Acc: 0.6810\n","Best Val Acc: 0.6810 | LR: 0.001000\n","Time: 39.4s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 9/70\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[""]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["üíæ Saved best model!\n","Train Loss: 0.8928, Train Acc: 0.6819\n","Val Loss: 0.8699, Val Acc: 0.6957\n","Best Val Acc: 0.6957 | LR: 0.001000\n","Time: 41.8s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 10/70\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[""]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["üíæ Saved best model!\n","Train Loss: 0.8579, Train Acc: 0.6971\n","Val Loss: 0.8168, Val Acc: 0.7145\n","Best Val Acc: 0.7145 | LR: 0.001000\n","Time: 41.7s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 11/70\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[""]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["üíæ Saved best model!\n","Train Loss: 0.8182, Train Acc: 0.7085\n","Val Loss: 0.8117, Val Acc: 0.7187\n","Best Val Acc: 0.7187 | LR: 0.001000\n","Time: 42.1s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 12/70\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[""]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["üíæ Saved best model!\n","Train Loss: 0.7928, Train Acc: 0.7223\n","Val Loss: 0.7685, Val Acc: 0.7302\n","Best Val Acc: 0.7302 | LR: 0.001000\n","Time: 39.4s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 13/70\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[""]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 0.7584, Train Acc: 0.7321\n","Val Loss: 0.7678, Val Acc: 0.7352\n","Best Val Acc: 0.7352 | LR: 0.001000\n","Time: 38.8s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 14/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["üíæ Saved best model!\n","Train Loss: 0.7327, Train Acc: 0.7426\n","Val Loss: 0.7119, Val Acc: 0.7504\n","Best Val Acc: 0.7504 | LR: 0.001000\n","Time: 40.7s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 15/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.7085, Train Acc: 0.7519\n","Val Loss: 0.7238, Val Acc: 0.7466\n","Best Val Acc: 0.7504 | LR: 0.001000\n","Time: 40.9s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 16/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["üíæ Saved best model!\n","Train Loss: 0.6883, Train Acc: 0.7594\n","Val Loss: 0.6656, Val Acc: 0.7693\n","Best Val Acc: 0.7693 | LR: 0.001000\n","Time: 40.9s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 17/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.6669, Train Acc: 0.7663\n","Val Loss: 0.6861, Val Acc: 0.7633\n","Best Val Acc: 0.7693 | LR: 0.001000\n","Time: 39.7s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 18/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["üíæ Saved best model!\n","Train Loss: 0.6493, Train Acc: 0.7725\n","Val Loss: 0.6439, Val Acc: 0.7790\n","Best Val Acc: 0.7790 | LR: 0.001000\n","Time: 41.9s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 19/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["üíæ Saved best model!\n","Train Loss: 0.6283, Train Acc: 0.7810\n","Val Loss: 0.6259, Val Acc: 0.7859\n","Best Val Acc: 0.7859 | LR: 0.001000\n","Time: 38.9s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 20/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["üíæ Saved best model!\n","Train Loss: 0.6107, Train Acc: 0.7886\n","Val Loss: 0.6178, Val Acc: 0.7878\n","Best Val Acc: 0.7878 | LR: 0.001000\n","Time: 38.7s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 21/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["üíæ Saved best model!\n","Train Loss: 0.5986, Train Acc: 0.7904\n","Val Loss: 0.5922, Val Acc: 0.7945\n","Best Val Acc: 0.7945 | LR: 0.001000\n","Time: 41.5s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 22/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.5844, Train Acc: 0.7951\n","Val Loss: 0.6016, Val Acc: 0.7936\n","Best Val Acc: 0.7945 | LR: 0.001000\n","Time: 42.7s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 23/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["üíæ Saved best model!\n","Train Loss: 0.5696, Train Acc: 0.8014\n","Val Loss: 0.5793, Val Acc: 0.7986\n","Best Val Acc: 0.7986 | LR: 0.001000\n","Time: 40.2s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 24/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.5672, Train Acc: 0.8004\n","Val Loss: 0.5924, Val Acc: 0.7910\n","Best Val Acc: 0.7986 | LR: 0.001000\n","Time: 40.2s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 25/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["üíæ Saved best model!\n","Train Loss: 0.5513, Train Acc: 0.8076\n","Val Loss: 0.5521, Val Acc: 0.8078\n","Best Val Acc: 0.8078 | LR: 0.001000\n","Time: 40.6s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 26/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.5420, Train Acc: 0.8108\n","Val Loss: 0.5831, Val Acc: 0.7991\n","Best Val Acc: 0.8078 | LR: 0.001000\n","Time: 39.6s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 27/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.5264, Train Acc: 0.8160\n","Val Loss: 0.5541, Val Acc: 0.8053\n","Best Val Acc: 0.8078 | LR: 0.001000\n","Time: 42.1s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 28/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.5166, Train Acc: 0.8173\n","Val Loss: 0.5518, Val Acc: 0.8077\n","Best Val Acc: 0.8078 | LR: 0.000500\n","Time: 41.2s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 29/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["üíæ Saved best model!\n","Train Loss: 0.4734, Train Acc: 0.8328\n","Val Loss: 0.5290, Val Acc: 0.8221\n","Best Val Acc: 0.8221 | LR: 0.000500\n","Time: 40.4s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 30/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["üíæ Saved best model!\n","Train Loss: 0.4601, Train Acc: 0.8392\n","Val Loss: 0.5175, Val Acc: 0.8242\n","Best Val Acc: 0.8242 | LR: 0.000500\n","Time: 41.2s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 31/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["üíæ Saved best model!\n","Train Loss: 0.4516, Train Acc: 0.8428\n","Val Loss: 0.5126, Val Acc: 0.8268\n","Best Val Acc: 0.8268 | LR: 0.000500\n","Time: 41.1s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 32/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.4380, Train Acc: 0.8471\n","Val Loss: 0.5227, Val Acc: 0.8242\n","Best Val Acc: 0.8268 | LR: 0.000500\n","Time: 39.4s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 33/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.4378, Train Acc: 0.8477\n","Val Loss: 0.5140, Val Acc: 0.8283\n","Best Val Acc: 0.8283 | LR: 0.000500\n","Time: 39.5s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 34/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.4377, Train Acc: 0.8449\n","Val Loss: 0.5296, Val Acc: 0.8187\n","Best Val Acc: 0.8283 | LR: 0.000500\n","Time: 40.8s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 35/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.4295, Train Acc: 0.8482\n","Val Loss: 0.5212, Val Acc: 0.8249\n","Best Val Acc: 0.8283 | LR: 0.000500\n","Time: 41.1s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 36/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["üíæ Saved best model!\n","Train Loss: 0.4241, Train Acc: 0.8520\n","Val Loss: 0.5004, Val Acc: 0.8281\n","Best Val Acc: 0.8283 | LR: 0.000250\n","Time: 41.0s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 37/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["üíæ Saved best model!\n","Train Loss: 0.3902, Train Acc: 0.8647\n","Val Loss: 0.4915, Val Acc: 0.8304\n","Best Val Acc: 0.8304 | LR: 0.000250\n","Time: 40.2s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 38/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["üíæ Saved best model!\n","Train Loss: 0.3917, Train Acc: 0.8626\n","Val Loss: 0.4899, Val Acc: 0.8343\n","Best Val Acc: 0.8343 | LR: 0.000250\n","Time: 38.2s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 39/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.3849, Train Acc: 0.8637\n","Val Loss: 0.4915, Val Acc: 0.8383\n","Best Val Acc: 0.8383 | LR: 0.000250\n","Time: 40.9s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 40/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.3870, Train Acc: 0.8643\n","Val Loss: 0.4938, Val Acc: 0.8357\n","Best Val Acc: 0.8383 | LR: 0.000250\n","Time: 42.0s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 41/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.3836, Train Acc: 0.8658\n","Val Loss: 0.4987, Val Acc: 0.8351\n","Best Val Acc: 0.8383 | LR: 0.000250\n","Time: 40.1s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 42/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.3782, Train Acc: 0.8674\n","Val Loss: 0.4893, Val Acc: 0.8385\n","Best Val Acc: 0.8385 | LR: 0.000250\n","Time: 40.9s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 43/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["üíæ Saved best model!\n","Train Loss: 0.3758, Train Acc: 0.8672\n","Val Loss: 0.4878, Val Acc: 0.8363\n","Best Val Acc: 0.8385 | LR: 0.000250\n","Time: 41.4s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 44/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.3713, Train Acc: 0.8692\n","Val Loss: 0.4939, Val Acc: 0.8396\n","Best Val Acc: 0.8396 | LR: 0.000250\n","Time: 42.0s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 45/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.3678, Train Acc: 0.8691\n","Val Loss: 0.4916, Val Acc: 0.8373\n","Best Val Acc: 0.8396 | LR: 0.000250\n","Time: 40.0s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 46/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.3695, Train Acc: 0.8702\n","Val Loss: 0.4952, Val Acc: 0.8365\n","Best Val Acc: 0.8396 | LR: 0.000250\n","Time: 40.9s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 47/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["üíæ Saved best model!\n","Train Loss: 0.3641, Train Acc: 0.8726\n","Val Loss: 0.4810, Val Acc: 0.8425\n","Best Val Acc: 0.8425 | LR: 0.000250\n","Time: 41.0s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 48/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.3647, Train Acc: 0.8742\n","Val Loss: 0.4892, Val Acc: 0.8352\n","Best Val Acc: 0.8425 | LR: 0.000250\n","Time: 40.9s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 49/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.3575, Train Acc: 0.8728\n","Val Loss: 0.4826, Val Acc: 0.8411\n","Best Val Acc: 0.8425 | LR: 0.000250\n","Time: 39.9s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 50/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.3589, Train Acc: 0.8738\n","Val Loss: 0.4843, Val Acc: 0.8438\n","Best Val Acc: 0.8438 | LR: 0.000250\n","Time: 40.3s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 51/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.3589, Train Acc: 0.8740\n","Val Loss: 0.4871, Val Acc: 0.8398\n","Best Val Acc: 0.8438 | LR: 0.000250\n","Time: 40.6s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 52/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["üíæ Saved best model!\n","Train Loss: 0.3566, Train Acc: 0.8746\n","Val Loss: 0.4786, Val Acc: 0.8428\n","Best Val Acc: 0.8438 | LR: 0.000250\n","Time: 39.9s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 53/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.3539, Train Acc: 0.8747\n","Val Loss: 0.4897, Val Acc: 0.8424\n","Best Val Acc: 0.8438 | LR: 0.000125\n","Time: 39.2s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 54/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.3396, Train Acc: 0.8799\n","Val Loss: 0.4812, Val Acc: 0.8391\n","Best Val Acc: 0.8438 | LR: 0.000125\n","Time: 40.6s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 55/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["üíæ Saved best model!\n","Train Loss: 0.3362, Train Acc: 0.8817\n","Val Loss: 0.4725, Val Acc: 0.8474\n","Best Val Acc: 0.8474 | LR: 0.000125\n","Time: 41.9s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 56/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.3366, Train Acc: 0.8828\n","Val Loss: 0.4759, Val Acc: 0.8456\n","Best Val Acc: 0.8474 | LR: 0.000125\n","Time: 40.8s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 57/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.3344, Train Acc: 0.8826\n","Val Loss: 0.4734, Val Acc: 0.8466\n","Best Val Acc: 0.8474 | LR: 0.000125\n","Time: 41.2s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 58/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.3308, Train Acc: 0.8833\n","Val Loss: 0.4790, Val Acc: 0.8442\n","Best Val Acc: 0.8474 | LR: 0.000063\n","Time: 40.6s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 59/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.3249, Train Acc: 0.8842\n","Val Loss: 0.4717, Val Acc: 0.8458\n","Best Val Acc: 0.8474 | LR: 0.000063\n","Time: 41.0s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 60/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["üíæ Saved best model!\n","Train Loss: 0.3261, Train Acc: 0.8860\n","Val Loss: 0.4671, Val Acc: 0.8486\n","Best Val Acc: 0.8486 | LR: 0.000063\n","Time: 40.3s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 61/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.3242, Train Acc: 0.8867\n","Val Loss: 0.4682, Val Acc: 0.8474\n","Best Val Acc: 0.8486 | LR: 0.000063\n","Time: 39.2s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 62/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["üíæ Saved best model!\n","Train Loss: 0.3190, Train Acc: 0.8878\n","Val Loss: 0.4655, Val Acc: 0.8479\n","Best Val Acc: 0.8486 | LR: 0.000063\n","Time: 39.1s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 63/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.3204, Train Acc: 0.8866\n","Val Loss: 0.4686, Val Acc: 0.8472\n","Best Val Acc: 0.8486 | LR: 0.000031\n","Time: 37.3s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 64/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.3166, Train Acc: 0.8888\n","Val Loss: 0.4698, Val Acc: 0.8470\n","Best Val Acc: 0.8486 | LR: 0.000031\n","Time: 39.0s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 65/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.3162, Train Acc: 0.8887\n","Val Loss: 0.4682, Val Acc: 0.8483\n","Best Val Acc: 0.8486 | LR: 0.000031\n","Time: 38.7s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 66/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.3113, Train Acc: 0.8910\n","Val Loss: 0.4717, Val Acc: 0.8479\n","Best Val Acc: 0.8486 | LR: 0.000016\n","Time: 38.8s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 67/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.3144, Train Acc: 0.8889\n","Val Loss: 0.4669, Val Acc: 0.8493\n","Best Val Acc: 0.8493 | LR: 0.000016\n","Time: 37.0s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 68/70\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.3149, Train Acc: 0.8882\n","Val Loss: 0.4667, Val Acc: 0.8493\n","Best Val Acc: 0.8493 | LR: 0.000016\n","Time: 38.6s\n","--------------------------------------------------\n","\n","\n","--------------------------------------------------\n","Epoch 69/70\n"]},{"output_type":"stream","name":"stderr","text":["                                                             "]},{"output_type":"stream","name":"stdout","text":["Early stopping triggered!\n","Training complete.\n"]},{"output_type":"stream","name":"stderr","text":["\r"]}]},{"cell_type":"code","source":["\"\"\"\n","history_path = f\"{DATA_DIR}/logs/conv0.1.json\"\n","saveHistory(history_conv1, history_path) # Saves the training metadata to a json file\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0nxPKj4HbQl3","executionInfo":{"status":"ok","timestamp":1758681970757,"user_tz":-60,"elapsed":56,"user":{"displayName":"David Okosa","userId":"00279339004346410402"}},"outputId":"ed3946df-8017-42de-a0cf-4c33624c45da"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["File Saved!\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"rFwmop_ZbHWh","executionInfo":{"status":"ok","timestamp":1758681885024,"user_tz":-60,"elapsed":19,"user":{"displayName":"David Okosa","userId":"00279339004346410402"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","if you wanted to add dropout to the CNN feature extractor, would you do it in only one layer?\n","\n","\n","No, you typically don't add dropout to only one layer of a CNN feature extractor. While there's no single \"correct\" way to do it, the most effective and common practice is to strategically place dropout layers in a few key locations to combat overfitting.\n","\n","Where to Add Dropout in a CNN\n","The purpose of dropout is to prevent the network from becoming too reliant on specific neurons, thereby improving its ability to generalize to new, unseen data. In a typical CNN architecture, overfitting is more likely to occur in the fully connected (dense) layers at the end of the network, as they have a large number of parameters. üß†\n","\n","\n","Here's the general strategy:\n","\n","After Fully Connected Layers: This is the most common and effective place to add dropout. Place a dropout layer with a rate of around 0.5 after each of the fully connected layers before the final output layer. The high parameter count in these layers makes them particularly susceptible to overfitting.\n","\n","\n","After Convolutional Layers: While less common, some research shows a benefit to adding dropout after convolutional layers, but with a much lower dropout rate (e.g., 0.1 to 0.2). This is because convolutional layers already have a form of built-in regularization due to parameter sharing. Using too high a dropout rate could lead to a loss of important spatial features.\n","\n","\n","Avoid Dropout After Max Pooling: You generally do not place a dropout layer directly after a max-pooling layer, as it would drop out the most salient feature (the maximum activation) from the pooling operation, which is counterproductive.\n","\n","The ideal approach is to experiment with different dropout rates and placements to find the configuration that works best for your specific model and dataset.\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":296},"id":"g7Gy7Y7HYZrV","executionInfo":{"status":"ok","timestamp":1758681886650,"user_tz":-60,"elapsed":1,"user":{"displayName":"David Okosa","userId":"00279339004346410402"}},"outputId":"ea7ad2c1-80a0-41a3-95c0-638580ffdece"},"execution_count":12,"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nif you wanted to add dropout to the CNN feature extractor, would you do it in only one layer?\\n\\n\\nNo, you typically don\\'t add dropout to only one layer of a CNN feature extractor. While there\\'s no single \"correct\" way to do it, the most effective and common practice is to strategically place dropout layers in a few key locations to combat overfitting.\\n\\nWhere to Add Dropout in a CNN\\nThe purpose of dropout is to prevent the network from becoming too reliant on specific neurons, thereby improving its ability to generalize to new, unseen data. In a typical CNN architecture, overfitting is more likely to occur in the fully connected (dense) layers at the end of the network, as they have a large number of parameters. üß†\\n\\n\\nHere\\'s the general strategy:\\n\\nAfter Fully Connected Layers: This is the most common and effective place to add dropout. Place a dropout layer with a rate of around 0.5 after each of the fully connected layers before the final output layer. The high parameter count in these layers makes them particularly susceptible to overfitting.\\n\\n\\nAfter Convolutional Layers: While less common, some research shows a benefit to adding dropout after convolutional layers, but with a much lower dropout rate (e.g., 0.1 to 0.2). This is because convolutional layers already have a form of built-in regularization due to parameter sharing. Using too high a dropout rate could lead to a loss of important spatial features.\\n\\n\\nAvoid Dropout After Max Pooling: You generally do not place a dropout layer directly after a max-pooling layer, as it would drop out the most salient feature (the maximum activation) from the pooling operation, which is counterproductive.\\n\\nThe ideal approach is to experiment with different dropout rates and placements to find the configuration that works best for your specific model and dataset.\\n'"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":["\"\"\"\n","Do you add dropout before or after the max pool?\n","\n","\n","Generally, you should add a dropout layer after the max-pooling layer. Here's why:\n","\n","Max pooling's role: The max-pooling layer's job is to distill the most important feature within a local region. It takes the maximum activation and discards the rest.\n","\n","Dropout's conflict: If you apply dropout before the max-pooling layer, you're randomly zeroing out some of the activations. This could potentially \"drop\" the very feature that the max-pooling layer would have selected as the most important one, undermining the purpose of the pooling operation.\n","\n","The typical order: The standard practice in a CNN feature extractor is to apply the layers in this sequence:\n","\n","Convolutional Layer\n","\n","Activation Function (like ReLU)\n","\n","Max-Pooling Layer\n","\n","Dropout Layer (optional)\n","\n","This order ensures that the model first extracts features, then activates them, then identifies the most salient features, and finally applies regularization via dropout.\n","\n","While dropout is most commonly and effectively used after fully connected layers, if you need to add it to a convolutional block, placing it after the pooling layer is the conventional and more logical choice.\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":296},"id":"HBrfpcTSYZgy","executionInfo":{"status":"ok","timestamp":1758681886704,"user_tz":-60,"elapsed":1,"user":{"displayName":"David Okosa","userId":"00279339004346410402"}},"outputId":"61cd2678-1d16-443d-f676-5ef04a904021"},"execution_count":13,"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nDo you add dropout before or after the max pool?\\n\\n\\nGenerally, you should add a dropout layer after the max-pooling layer. Here\\'s why:\\n\\nMax pooling\\'s role: The max-pooling layer\\'s job is to distill the most important feature within a local region. It takes the maximum activation and discards the rest.\\n\\nDropout\\'s conflict: If you apply dropout before the max-pooling layer, you\\'re randomly zeroing out some of the activations. This could potentially \"drop\" the very feature that the max-pooling layer would have selected as the most important one, undermining the purpose of the pooling operation.\\n\\nThe typical order: The standard practice in a CNN feature extractor is to apply the layers in this sequence:\\n\\nConvolutional Layer\\n\\nActivation Function (like ReLU)\\n\\nMax-Pooling Layer\\n\\nDropout Layer (optional)\\n\\nThis order ensures that the model first extracts features, then activates them, then identifies the most salient features, and finally applies regularization via dropout.\\n\\nWhile dropout is most commonly and effectively used after fully connected layers, if you need to add it to a convolutional block, placing it after the pooling layer is the conventional and more logical choice.\\n'"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}]}]}